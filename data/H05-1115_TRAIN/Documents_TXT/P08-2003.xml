<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">We consider the problem of answering complex questions that require inferencing andsynthesizing information from multiple documents and can be seen as a kind of topic-oriented, informative multi-document summarization.</S>
		<S sid ="2" ssid = "2">The stochastic, graph-based methodfor computing the relative importance of textual units (i.e. sentences) is very successfulin generic summarization.</S>
		<S sid ="3" ssid = "3">In this method,a sentence is encoded as a vector in whicheach component represents the occurrence frequency (TF*IDF) of a word.</S>
		<S sid ="4" ssid = "4">However, themajor limitation of the TF*IDF approach isthat it only retains the frequency of the wordsand does not take into account the sequence,syntactic and semantic information.</S>
		<S sid ="5" ssid = "5">In this paper, we study the impact of syntactic and shallow semantic information in the graph-basedmethod for answering complex questions.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="6" ssid = "6">After having made substantial headway in factoidand list questions, researchers have turned their attention to more complex information needs that cannot be answered by simply extracting named entities like persons, organizations, locations, dates,etc. Unlike informationally-simple factoid questions, complex questions often seek multiple different types of information simultaneously and do notpresupposed that one single answer could meet allof its information needs.</S>
			<S sid ="7" ssid = "7">For example, with complexquestions like “What are the causes of AIDS?”, thewider focus of this question suggests that the submitter may not have a single or well-defined infor mation need and therefore may be amenable to receiving additional supporting information that is relevant to some (as yet) undefined informational goal.This type of questions require inferencing and synthesizing information from multiple documents.</S>
			<S sid ="8" ssid = "8">InNatural Language Processing (NLP), this information synthesis can be seen as a kind of topic-oriented,informative multi-document summarization, wherethe goal is to produce a single text as a compressedversion of a set of documents with a minimum lossof relevant information.</S>
			<S sid ="9" ssid = "9">Recently, the graph-based method (LexRank) isapplied successfully to generic, multidocumentsummarization (Erkan and Radev, 2004).</S>
			<S sid ="10" ssid = "10">A topic-sensitive LexRank is proposed in (Otterbacher et al.,2005).</S>
			<S sid ="11" ssid = "11">In this method, a sentence is mapped to a vector in which each element represents the occurrencefrequency (TF*IDF) of a word.</S>
			<S sid ="12" ssid = "12">However, the majorlimitation of the TF*IDF approach is that it only retains the frequency of the words and does not takeinto account the sequence, syntactic and semanticinformation thus cannot distinguish between “Thehero killed the villain” and “The villain killed thehero”.</S>
			<S sid ="13" ssid = "13">The task like answering complex questionsthat requires the use of more complex syntactic andsemantics, the approaches with only TF*IDF are often inadequate to perform fine-level textual analysis.</S>
			<S sid ="14" ssid = "14">In this paper, we extensively study the impactof syntactic and shallow semantic information inmeasuring similarity between the sentences in therandom walk model for answering complex questions.</S>
			<S sid ="15" ssid = "15">We argue that for this task, similarity measures based on syntactic and semantic informationperforms better and can be used to characterize the 9 relation between a question and a sentence (answer)in a more effective way than the traditional TF*IDFbased similarity measures.</S>
	</SECTION>
	<SECTION title="Graph-based Random Walk Model forText Summarization. " number = "2">
			<S sid ="16" ssid = "1">In (Erkan and Radev, 2004), the concept of graph-based centrality is used to rank a set of sentences,in producing generic multi-document summaries.</S>
			<S sid ="17" ssid = "2">Asimilarity graph is produced where each node represents a sentence in the collection and the edges between nodes measure the cosine similarity betweenthe respective pair of sentences.</S>
			<S sid ="18" ssid = "3">Each sentence isrepresented as a vector of term specific weights.</S>
			<S sid ="19" ssid = "4">Theterm specific weights in the sentence vectors areproducts of term frequency (tf) and inverse document frequency (idf).</S>
			<S sid ="20" ssid = "5">The degree of a given nodeis an indication of how much important the sentenceis.</S>
			<S sid ="21" ssid = "6">To apply LexRank to query-focused context, atopic-sensitive version of LexRank is proposed in(Otterbacher et al., 2005).</S>
			<S sid ="22" ssid = "7">The score of a sentence isdetermined by a mixture model: p(s|q) = d× rel(s|q)?z?C rel(z|q) + (1- d) ×?v?C sim(s, v)?z?C sim(z, v) × p(v|q) (1) Where, p(s|q) is the score of a sentence s given aquestion q, is determined as the sum of its relevanceto the question (i.e. rel(s|q)) and the similarity toother sentences in the collection (i.e. sim(s, v)).The denominators in both terms are for normalization.</S>
			<S sid ="23" ssid = "8">C is the set of all sentences in the collection.The value of the parameter d which we call “bias”,is a trade-off between two terms in the equation andis set empirically.</S>
			<S sid ="24" ssid = "9">We claim that for a complex tasklike answering complex questions where the related-ness between the query sentences and the documentsentences is an important factor, the graph-basedrandom walk model of ranking sentences would perform better if we could encode the syntactic and semantic information instead of just the bag of word(i.e. TF*IDF) information in calculating the similarity between sentences.</S>
			<S sid ="25" ssid = "10">Thus, our mixture model foranswering complex questions is: p(s|q) = d× TREESIM(s, q) + (1- d)× ?v?C TREESIM(s, v)× p(v|q) (2) Figure 1: Example of semantic trees Where TREESIM(s,q) is the normalized syntactic(and/or semantic) similarity between the query (q)and the document sentence (s) and C is the set ofall sentences in the collection.</S>
			<S sid ="26" ssid = "11">In cases where thequery is composed of two or more sentences, wecompute the similarity between the document sentence (s) and each of the query-sentences (qi) thenwe take the average of the scores.</S>
	</SECTION>
	<SECTION title="Encoding Syntactic and ShallowSemantic Structures. " number = "3">
			<S sid ="27" ssid = "1">Encoding syntactic structure is easier and straightforward.</S>
			<S sid ="28" ssid = "2">Given a sentence (or query), we first parseit into a syntactic tree using a syntactic parser (i.e.Charniak parser) and then we calculate the similaritybetween the two trees using the general tree kernelfunction (Section 4.1).</S>
			<S sid ="29" ssid = "3">Initiatives such as PropBank (PB) (Kingsbury andPalmer, 2002) have made possible the design ofaccurate automatic Semantic Role Labeling (SRL)systems like ASSERT (Hacioglu et al., 2003).</S>
			<S sid ="30" ssid = "4">Forexample, consider the PB annotation: [ARG0 all][TARGET use][ARG1 the frenchfranc][ARG2 as their currency] Such annotation can be used to design a shallowsemantic representation that can be matched againstother semantically similar sentences, e.g. [ARG0 the Vatican][TARGET use][ARG1 theItalian lira][ARG2 as their currency] In order to calculate the semantic similarity between the sentences, we first represent the annotatedsentence using the tree structures like Figure 1 whichwe call Semantic Tree (ST).</S>
			<S sid ="31" ssid = "5">In the semantic tree, arguments are replaced with the most important word-often referred to as the semantic head.</S>
			<S sid ="32" ssid = "6">The sentences may contain one or more subordinate clauses.</S>
			<S sid ="33" ssid = "7">For example the sentence, “the Vatican, located wholly within Italy uses the Italian lira 10 Figure 2: Two STs composing a STN as their currency.” gives the STs as in Figure 2.</S>
			<S sid ="34" ssid = "8">Aswe can see in Figure 2(A), when an argument nodecorresponds to an entire subordinate clause, we label its leaf with ST , e.g. the leaf of ARG0.</S>
			<S sid ="35" ssid = "9">Such STnode is actually the root of the subordinate clausein Figure 2(B).</S>
			<S sid ="36" ssid = "10">If taken separately, such STs do notexpress the whole meaning of the sentence, hence itis more accurate to define a single structure encoding the dependency between the two predicates as inFigure 2(C).</S>
			<S sid ="37" ssid = "11">We refer to this kind of nested STs asSTNs.</S>
	</SECTION>
	<SECTION title="Syntactic and Semantic Kernels for Text. " number = "4">
			<S sid ="38" ssid = "1">4.1 Tree Kernels.</S>
			<S sid ="39" ssid = "2">Once we build the trees (syntactic or semantic),our next task is to measure the similarity between the trees.</S>
			<S sid ="40" ssid = "3">For this, every tree T is represented by an m dimensional vector v(T ) =(v1(T ), v2(T ), · · · vm(T )), where the i-th elementvi(T ) is the number of occurrences of the i-th treefragment in tree T . The tree fragments of a tree areall of its sub-trees which include at least one production with the restriction that no production rules canbe broken into incomplete parts.</S>
			<S sid ="41" ssid = "4">Implicitly we enumerate all the possible tree fragments 1, 2, · · · ,m. These fragments are the axisof this m-dimensional space.</S>
			<S sid ="42" ssid = "5">Note that this couldbe done only implicitly, since the number m is extremely large.</S>
			<S sid ="43" ssid = "6">Because of this, (Collins and Duffy,2001) defines the tree kernel algorithm whose computational complexity does not depend on m. Wefollowed the similar approach to compute the treekernel between two syntactic trees.</S>
			<S sid ="44" ssid = "7">4.2 Shallow Semantic Tree Kernel (SSTK).</S>
			<S sid ="45" ssid = "8">Note that, the tree kernel (TK) function defined in(Collins and Duffy, 2001) computes the number ofcommon subtrees between two trees.</S>
			<S sid ="46" ssid = "9">Such subtreesare subject to the constraint that their nodes are takenwith all or none of the children they have in the original tree.</S>
			<S sid ="47" ssid = "10">Though, this definition of subtrees makesthe TK function appropriate for syntactic trees butat the same time makes it not well suited for the semantic trees (ST) defined in Section 3.</S>
			<S sid ="48" ssid = "11">For instance,although the two STs of Figure 1 share most of thesubtrees rooted in the ST node, the kernel definedabove computes no match.</S>
			<S sid ="49" ssid = "12">The critical aspect of the TK function is that theproductions of two evaluated nodes have to be identical to allow the match of further descendants.</S>
			<S sid ="50" ssid = "13">Thismeans that common substructures cannot be composed by a node with only some of its children asan effective ST representation would require.</S>
			<S sid ="51" ssid = "14">Moschitti et al.</S>
			<S sid ="52" ssid = "15">(2007) solve this problem by designingthe Shallow Semantic Tree Kernel (SSTK) whichallows to match portions of a ST. We followed thesimilar approach to compute the SSTK.</S>
	</SECTION>
	<SECTION title="Experiments. " number = "5">
			<S sid ="53" ssid = "1">5.1 Evaluation Setup.</S>
			<S sid ="54" ssid = "2">The Document Understanding Conference (DUC)series is run by the National Institute of Standardsand Technology (NIST) to further progress in sum-marization and enable researchers to participate inlarge-scale experiments.</S>
			<S sid ="55" ssid = "3">We used the DUC 2007datasets for evaluation.</S>
			<S sid ="56" ssid = "4">We carried out automatic evaluation of our summaries using ROUGE (Lin, 2004) toolkit, whichhas been widely adopted by DUC for automaticsummarization evaluation.</S>
			<S sid ="57" ssid = "5">It measures summaryquality by counting overlapping units such as then-gram (ROUGE-N), word sequences (ROUGE-Land ROUGE-W) and word pairs (ROUGES andROUGESU) between the candidate summary andthe reference summary.</S>
			<S sid ="58" ssid = "6">ROUGE parameters wereset as the same as DUC 2007 evaluation setup.</S>
			<S sid ="59" ssid = "7">Allthe ROUGE measures were calculated by runningROUGE1.5.5 with stemming but no removal ofstopwords.</S>
			<S sid ="60" ssid = "8">The ROUGE run-time parameters are: ROUGE-1.5.5.pl2 -1 -u -r 1000 -t 0 -n 4 -w 1.2-m -l 250 -a 11 The purpose of our experiments is to study theimpact of the syntactic and semantic representationfor complex question answering task.</S>
			<S sid ="61" ssid = "9">To accomplishthis, we generate summaries for the topics of DUC2007 by each of our four systems defined as below:(1) TF*IDF: system is the original topic-sensitiveLexRank described in Section 2 that uses the similarity measures based on tf*idf.(2) SYN: system measures the similarity betweenthe sentences using the syntactic tree and the general tree kernel function defined in Section 4.1.(3) SEM: system measures the similarity betweenthe sentences using the shallow semantic tree andthe shallow semantic tree kernel function defined inSection 4.2.(4) SYNSEM: system measures the similarity between the sentences using both the syntactic andshallow semantic trees and their associated kernels.For each sentence it measures the syntactic and semantic similarity with the query and takes the average of these measures.</S>
			<S sid ="62" ssid = "10">5.2 Evaluation Results.</S>
			<S sid ="63" ssid = "11">The comparison between the systems in terms oftheir F-scores is given in Table 1.</S>
			<S sid ="64" ssid = "12">The SYN systemimproves the ROUGE-1, ROUGE-L and ROUGE-W scores over the TF*IDF system by 2.84%, 0.53%and 2.14% respectively.</S>
			<S sid ="65" ssid = "13">The SEM system improves the ROUGE-1, ROUGE-L, ROUGE-W, andROUGESU scores over the TF*IDF system by8.46%, 6.54%, 6.56%, and 11.68%, and over theSYN system by 5.46%, 5.98%, 4.33%, and 12.97%respectively.</S>
			<S sid ="66" ssid = "14">The SYNSEM system improves theROUGE1, ROUGE-L, ROUGE-W, and ROUGESU scores over the TF*IDF system by 4.64%,1.63%, 2.15%, and 4.06%, and over the SYN system by 1.74%, 1.09%, 0%, and 5.26% respectively.The SEM system improves the ROUGE-1, ROUGE-L, ROUGE-W, and ROUGESU scores over theSYNSEM system by 3.65%, 4.84%, 4.32%, and7.33% respectively which indicates that includingsyntactic feature with the semantic feature degradesthe performance.</S>
	</SECTION>
	<SECTION title="Conclusion. " number = "6">
</PAPER>
