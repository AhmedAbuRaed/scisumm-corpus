<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">Opinion Question Answering (OpinionQA), which aims to find the authors’ sentimental opinions on a specific target, ismore challenging than traditional fact-based question answering problems.</S>
		<S sid ="2" ssid = "2">Toextract the opinion oriented answers, weneed to consider both topic relevance andopinion sentiment issues.</S>
		<S sid ="3" ssid = "3">Current solutions to this problem are mostly ad-hoccombinations of question topic information and opinion information.</S>
		<S sid ="4" ssid = "4">In this paper, we propose an Opinion PageRankmodel and an Opinion HITS model to fullyexplore the information from different relations among questions and answers, answers and answers, and topics and opinions.</S>
		<S sid ="5" ssid = "5">By fully exploiting these relations,the experiment results show that our proposed algorithms outperform several stateof the art baselines on benchmark data set.A gain of over 10% in F scores is achievedas compared to many other systems.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="6" ssid = "6">Question Answering (QA), which aims to provide answers to human-generated questions automatically, is an important research area in natural language processing (NLP) and much progresshas been made on this topic in previous years.However, the objective of most state-of-the-art QAsystems is to find answers to factual questions,such as “What is the longest river in the UnitedStates?” and “Who is Andrew Carnegie?” In fact,rather than factual information, people would alsolike to know about others’ opinions, thoughts andfeelings toward some specific objects, people andevents.</S>
			<S sid ="7" ssid = "7">Some examples of these questions are:“How is Bush’s decision not to ratify the KyotoProtocol looked upon by Japan and other US al lies?”(Stoyanov et al., 2005) and “Why do people like Subway Sandwiches?” from TAC 2008(Dang, 2008).</S>
			<S sid ="8" ssid = "8">Systems designed to deal with suchquestions are called opinion QA systems.</S>
			<S sid ="9" ssid = "9">Researchers (Stoyanov et al., 2005) have found thatopinion questions have very different characteristics when compared with fact-based questions:opinion questions are often much longer, morelikely to represent partial answers rather than complete answers and vary much more widely.</S>
			<S sid ="10" ssid = "10">Thesefeatures make opinion QA a harder problem totackle than fact-based QA.</S>
			<S sid ="11" ssid = "11">Also as shown in (Stoyanov et al., 2005), directly applying previous systems designed for fact-based QA onto opinion QAtasks would not achieve good performances.</S>
			<S sid ="12" ssid = "12">Similar to other complex QA tasks (Chen et al.,2006; Cui et al., 2007), the problem of opinion QAcan be viewed as a sentence ranking problem.</S>
			<S sid ="13" ssid = "13">TheOpinion QA task needs to consider not only thetopic relevance of a sentence (to identify whetherthis sentence matches the topic of the question)but also the sentiment of a sentence (to identifythe opinion polarity of a sentence).</S>
			<S sid ="14" ssid = "14">Current solutions to opinion QA tasks are generally in ad hocstyles: the topic score and the opinion score areusually separately calculated and then combinedvia a linear combination (Varma et al., 2008) orjust filter out the candidate without matching thequestion sentiment (Stoyanov et al., 2005).</S>
			<S sid ="15" ssid = "15">However, topic and opinion are not independent in reality.</S>
			<S sid ="16" ssid = "16">The opinion words are closely associatedwith their contexts.</S>
			<S sid ="17" ssid = "17">Another problem is that existing algorithms compute the score for each answercandidate individually, in other words, they do notconsider the relations between answer candidates.The quality of a answer candidate is not only determined by the relevance to the question, but alsoby other candidates.</S>
			<S sid ="18" ssid = "18">For example, the good answer may be mentioned by many candidates.</S>
			<S sid ="19" ssid = "19">In this paper, we propose two models to address the above limitations of previous sentence 737 ranking models.</S>
			<S sid ="20" ssid = "20">We incorporate both the topicrelevance information and the opinion sentimentinformation into our sentence ranking procedure.Meanwhile, our sentence ranking models couldnaturally consider the relationships between different answer candidates.</S>
			<S sid ="21" ssid = "21">More specifically, ourfirst model, called Opinion PageRank, incorporates opinion sentiment information into the graphmodel as a condition.</S>
			<S sid ="22" ssid = "22">The second model, calledOpinion HITS model, considers the sentences asauthorities and both question topic informationand opinion sentiment information as hubs.</S>
			<S sid ="23" ssid = "23">Theexperiment results on the TAC QA data set demonstrate the effectiveness of the proposed RandomWalk based methods.</S>
			<S sid ="24" ssid = "24">Our proposed method performs better than the best method in the TAC 2008competition.</S>
			<S sid ="25" ssid = "25">The rest of this paper is organized as follows:Section 2 introduces some related works.</S>
			<S sid ="26" ssid = "26">We willdiscuss our proposed models in Section 3.</S>
			<S sid ="27" ssid = "27">In Section 4, we present an overview of our opinion QAsystem.</S>
			<S sid ="28" ssid = "28">The experiment results are shown in Section 5.</S>
			<S sid ="29" ssid = "29">Finally, Section 6 concludes this paper andprovides possible directions for future work.</S>
	</SECTION>
	<SECTION title="Related Work. " number = "2">
			<S sid ="30" ssid = "1">Few previous studies have been done on opinion QA.</S>
			<S sid ="31" ssid = "2">To our best knowledge, (Stoyanov etal., 2005) first created an opinion QA corpusOpQA.</S>
			<S sid ="32" ssid = "3">They find that opinion QA is a more challenging task than factual question answering, andthey point out that traditional fact-based QA approaches may have difficulty on opinion QA tasksif unchanged.</S>
			<S sid ="33" ssid = "4">(Somasundaran et al., 2007) arguesthat making finer grained distinction of subjectivetypes (sentiment and arguing) further improves theQA system.</S>
			<S sid ="34" ssid = "5">For non-English opinion QA, (Ku etal., 2007) creates a Chinese opinion QA corpus.They classify opinion questions into six types andconstruct three components to retrieve opinion answers.</S>
			<S sid ="35" ssid = "6">Relevant answers are further processed byfocus detection, opinion scope identification andpolarity detection.</S>
			<S sid ="36" ssid = "7">Some works on opinion mining are motivated by opinion question answering.(Yu and Hatzivassiloglou, 2003) discusses a necessary component for an opinion question answering system: separating opinions from fact at boththe document and sentence level.</S>
			<S sid ="37" ssid = "8">(SooMin andHovy, 2005) addresses another important component of opinion question answering: finding opinion holders.</S>
			<S sid ="38" ssid = "9">More recently, TAC 2008 QA track (evolvedfrom TREC) focuses on finding answers to opinion questions (Dang, 2008).</S>
			<S sid ="39" ssid = "10">Opinion questionsretrieve sentences or passages as answers whichare relevant for both question topic and questionsentiment.</S>
			<S sid ="40" ssid = "11">Most TAC participants employ a strategy of calculating two types of scores for answercandidates, which are the topic score measure andthe opinion score measure (the opinion information expressed in the answer candidate).</S>
			<S sid ="41" ssid = "12">However, most approaches simply combined these twoscores by a weighted sum, or removed candidatesthat didn’t match the polarity of questions, in orderto extract the opinion answers.</S>
			<S sid ="42" ssid = "13">Algorithms based on Markov Random Walkhave been proposed to solve different kinds ofranking problems, most of which are inspired bythe PageRank algorithm (Page et al., 1998) and theHITS algorithm (Kleinberg, 1999).</S>
			<S sid ="43" ssid = "14">These two algorithms were initially applied to the task of Websearch and some of their variants have been provedsuccessful in a number of applications, includingfact-based QA and text summarization (Erkan andRadev, 2004; Mihalcea and Tarau, 2004; Otter-bacher et al., 2005; Wan and Yang, 2008).</S>
			<S sid ="44" ssid = "15">Generally, such models would first construct a directedor undirected graph to represent the relationshipbetween sentences and then certain graph-basedranking methods are applied on the graph to compute the ranking score for each sentence.</S>
			<S sid ="45" ssid = "16">Sentences with high scores are then added into theanswer set or the summary.</S>
			<S sid ="46" ssid = "17">However, to the bestof our knowledge, all previous Markov RandomWalk-based sentence ranking models only makeuse of topic relevance information, i.e. whetherthis sentence is relevant to the fact we are lookingfor, thus they are limited to fact-based QA tasks.To solve the opinion QA problems, we need toconsider both topic and sentiment in a non-trivialmanner.</S>
	</SECTION>
	<SECTION title="Our Models for Opinion SentenceRanking. " number = "3">
</PAPER>
